{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img\n",
    "     img align=\"left\"\n",
    "     src=\"src/uni_logo_black.png\"\n",
    "     alt=\"Universität Bielefeld\"\n",
    "     width=\"20%\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 10: Meta-Learning with Reptile\n",
    "#### József Lurvig\n",
    "19. July 2022\n",
    "\n",
    "*A. Nichol, J. Achiam, J. Schulman (2018): On First-Order Meta-Learning Algorithms*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Many tasks: for every task a different AI needs to be trained and training takes long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- First order MAML\n",
    "- Reptile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human vs ML\n",
    "ML systems have surpassed humans at many tasks, but they need far more data to reach the same level of performance. This comparison is however not fair, because these algorithms have to start from scratch, humans enter the task with a large amount of prior/background knowledge, encoded in their brains and DNA. Humans don't learn every time from scratch, but they are fine-tuning and recombining a set of pre-existing skills.\n",
    "\n",
    "Tenenbaum et al.: This can be explained as Bayesian inference --> the key is to make our algorithms more Bayesian. This is however difficult. (should make use of deep neural networks and should be computationally feasible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-agnostic meta-learning (MAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-Agnostic Meta-Learning (MAML) was introduced in 2017 by Chelsea Finn et al. Given a sequence of tasks, the parameters of a given model are trained such that few iterations of gradient descent with few training data from a new task will lead to good generalization performance on that task. MAML \"trains the model to be easy to fine-tune.\" MAML was successfully applied to few-shot image classification benchmarks and to policy-gradient-based reinforcement learning. **[[1](https://en.wikipedia.org/wiki/Meta_learning_(computer_science))]**\n",
    "\n",
    "Compatible with any model trained with gradient descent and applicable to a variety of different learning problems. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. **[[2](https://arxiv.org/abs/1703.03400)]**\n",
    "\n",
    "1. MAML is a powerful tool for meta-learning that can be used to improve the performance of machine learning models.\n",
    "2. MAML can be used to train models on a variety of tasks and then fine-tune them for a specific task.\n",
    "3. MAML is efficient and can be used to train models on large datasets.\n",
    "4. MAML is scalable and can be used to train models on a variety of hardware platforms.\n",
    "5. MAML is open source and available for use by anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test leírás\n",
    "Access a distribution over tasks, they sample a training set of tasks and a test set of tasks.\n",
    "\n",
    "Algorithm gets trainig set of tasks and produces agent, that has good average performance on the test set of tasks. Reenforcement reward = learning quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reptile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a new first-order gradient-based meta-learning algorithm\n",
    "\n",
    "The Reptile algorithm is as follows:\n",
    "> Initialize $\\phi$\\\n",
    "> **for** *i* **do**\n",
    "> > Sample $\\tau$\\\n",
    "> > Compute $\\tilde{\\phi}$\\\n",
    "> > Update $\\phi$\n",
    ">\n",
    "> **end for**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: One-Dimensional Sine Wave Regression\n",
    "\n",
    "- let's look at: task = 1D sine regression\n",
    "\n",
    "1. $f(x) = a\\cdot{\\sin(x+b)}$, where amplitude $a \\sim U([0.1, 5])$ and phase $b \\sim U([0, 2\\pi])$\n",
    "1. Sample $x_{1}, x_{2}, \\dots, x_{p}$\n",
    "1. Learner sees $(x_{1}, y_{1}), (x_{2}, y_{2}), \\dots, (x_{p}, y_{p})$ and predicts $f(x)$\n",
    "1. Loss is $L_{\\tau}(f) = \\int_{-5}^{5}dx||f(x)-f_{\\tau}(x)||^{2}$\n",
    "\n",
    "Note that $\\mathbb{E}_{\\tau}[f_{\\tau}()x]=0$ due to the random phase $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- few-shot regression\n",
    "- training on 10 sampled points\n",
    "- 32 gradient steps\n",
    "- MLP with layers $1 \\to 64 \\to 64 \\to 1$\n",
    "\n",
    "| ![](src/sine_maml.png) | ![](src/sine_reptile.png) |\n",
    "| :----: | :----: |\n",
    "| After MAML training | After Reptile training |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "- two alternative explanations of why Reptile works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Leading Order Expansion of the Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Finding a Point Near All Solution Manifolds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "59f3145cc67fcda0343c2852f1f97113a2e6e98841e887156424448e7071ad54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
