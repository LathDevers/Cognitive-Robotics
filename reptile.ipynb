{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img\n",
    "     img align=\"left\"\n",
    "     src=\"src/uni_logo_white.png\"\n",
    "     alt=\"Universität Bielefeld\"\n",
    "     width=\"20%\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 10: Meta-Learning with Reptile\n",
    "#### József Lurvig\n",
    "*19. July 2022*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "*A. Nichol, J. Achiam, J. Schulman (2018): On First-Order Meta-Learning Algorithms*\n",
    "\n",
    "This paper considers meta-learning problems, where there is a distribution of tasks, and we would like to obtain an agent that performs well (i.e., learns quickly) when presented with a previously unseen task sampled from this distribution.\n",
    "\n",
    "Problem: Many tasks: for every task a different AI needs to be trained and training takes long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "- First order MAML\n",
    "- Reptile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human vs Machine Learning\n",
    "ML systems have surpassed humans at many tasks, but they need far more data to reach the same level of performance. This comparison is however not fair, because these algorithms have to start from scratch, humans enter the task with a large amount of prior/background knowledge, encoded in their brains and DNA. Humans don't learn every time from scratch, but they are fine-tuning and recombining a set of pre-existing skills.\n",
    "\n",
    "Tenenbaum et al.: This can be explained as Bayesian inference --> the key is to make our algorithms more Bayesian. This is however difficult. (should make use of deep neural networks and should be computationally feasible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- seeks to directly optimize a fast-learning algorithm\n",
    "- we have a distribution over tasks $\\to$ a training set and a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-agnostic meta-learning (MAML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-Agnostic Meta-Learning (MAML) was introduced in 2017 by Chelsea Finn et al. Given a sequence of tasks, the parameters of a given model are trained such that few iterations of gradient descent with few training data from a new task will lead to good generalization performance on that task. MAML \"trains the model to be easy to fine-tune.\" MAML was successfully applied to few-shot image classification benchmarks and to policy-gradient-based reinforcement learning. **[[3](https://en.wikipedia.org/wiki/Meta_learning_(computer_science))]**\n",
    "\n",
    "Compatible with any model trained with gradient descent and applicable to a variety of different learning problems. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. **[[4](https://arxiv.org/abs/1703.03400)]**\n",
    "\n",
    "1. MAML is a powerful tool for meta-learning that can be used to improve the performance of machine learning models.\n",
    "2. MAML can be used to train models on a variety of tasks and then fine-tune them for a specific task.\n",
    "3. MAML is efficient and can be used to train models on large datasets.\n",
    "4. MAML is scalable and can be used to train models on a variety of hardware platforms.\n",
    "5. MAML is open source and available for use by anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access a distribution over tasks, they sample a training set of tasks and a test set of tasks.\n",
    "\n",
    "Algorithm gets trainig set of tasks and produces agent, that has good average performance on the test set of tasks. Reenforcement reward = learning quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reptile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a new first-order gradient-based meta-learning algorithm\n",
    "\n",
    "#### Reptile algorithm *(serial version)*\n",
    "> *Initialize $\\phi$*                    *initial parameter vector*\\\n",
    "> **for** *i* **do**\n",
    "> > *Sample $\\tau$*                 *$\\tau$ : task, $L_{\\tau}$ : loss, $\\tilde{\\phi}$ weight vectors*\\\n",
    "> > *Compute $\\tilde{\\phi}$*              *$\\tilde{\\phi} = U_{\\tau}^{k}(\\phi)$, denoting $k$ steps of SGD or Adam*\\\n",
    "> > *Update $\\phi$*                 *$\\phi \\leftarrow \\phi + \\epsilon (\\tilde{\\phi} - \\phi)$*\n",
    "> >\n",
    "> **end**\\\n",
    "> *Return $\\phi$* \n",
    "\n",
    "#### Reptile algorithm *(batched version)*\n",
    "> *Initialize $\\phi$*                                                      *vector of initial parameters of the model*\\\n",
    "> *Sample $\\tau_{1}, \\tau_{2}, \\dots, \\tau_{n}$*                                 *subset of tasks*\\\n",
    "> **for** $i \\leftarrow 1$ **to** $n_{epochs}$ **do**\n",
    "> > **for** $j \\leftarrow 1$ **to** $batch\\_size$ **do**\n",
    "> > > *$W \\leftarrow SGD(L_{\\tau_{i}}, \\phi, k)$*                    *$k$ : number of SGD steps*\n",
    "> > >\n",
    "> > **end**\\\n",
    "> > *Update $\\phi$*                                                  *$\\phi \\leftarrow \\phi + \\frac{\\epsilon}{k}\\sum_{i=1}^n (W_i - \\phi)$*\n",
    "> >\n",
    "> **end**\\\n",
    "> *Return $\\phi$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: One-Dimensional Sine Wave Regression\n",
    "\n",
    "- let's look at: task = 1D sine regression\n",
    "\n",
    "1. $f(x) = a\\cdot{\\sin(x+b)}$, where amplitude $a \\sim U([0.1, 5])$ and phase $b \\sim U([0, 2\\pi])$\n",
    "1. Sample $x_{1}, x_{2}, \\dots, x_{p}$\n",
    "1. Learner sees $(x_{1}, y_{1}), (x_{2}, y_{2}), \\dots, (x_{p}, y_{p})$ and predicts $f(x)$\n",
    "1. Loss is $L_{\\tau}(f) = \\int_{-5}^{5}dx||f(x)-f_{\\tau}(x)||^{2}$\n",
    "\n",
    "Note that $\\mathbb{E}_{\\tau}[f_{\\tau}()x]=0$ due to the random phase $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "- few-shot regression\n",
    "- training on 10 sampled points\n",
    "- 32 gradient steps\n",
    "- MLP with layers $1 \\to 64 \\to 64 \\to 1$\n",
    "\n",
    "| <img src=\"src/sine_maml.png\" width=\"320\"/> | <img src=\"src/sine_reptile.png\" width=\"320\"/> |\n",
    "| :----: | :----: |\n",
    "| After MAML training | After Reptile training |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/parallels/supervised-reptile/supervised_reptile # && python3 reptile-sinewaves-demo.py'\n",
      "/media/psf/Home/Downloads/Cognitive Robotics\n"
     ]
    }
   ],
   "source": [
    "cd ~/supervised-reptile/supervised_reptile && python3 reptile-sinewaves-demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "- two alternative explanations of why Reptile works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Leading Order Expansion of the Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taylor series expansion to approximate the update performed by\n",
    "  - Reptile and\n",
    "  - MAML\n",
    "Result:\n",
    "- both contain the same leading-order terms\n",
    "  - 1st term: minimizes expected loss *(joint training)*\n",
    "  - 2nd term: maximizes within-task generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Finding a Point Near All Solution Manifolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-941c3e69247b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-941c3e69247b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NOTE: #NÉZD MEG EZT A VIDEÓT!!!\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "NOTE: #NÉZD MEG EZT A VIDEÓT!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/joschu/f503500cda64f2ce87c8288906b09e2d#file-reptile-sinewaves-demo-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1] A. Nichol, J. Achiam, J. Schulman (2018):** *On First-Order Meta-Learning Algorithms*\\\n",
    "**[2] A. Nichol and J. Schulman (2018):** *Reptile: a Scalable Meta-Learning Algorithm*\\\n",
    "**[3] Wikipedia (accessed July 2022):** *Meta learning (computer science) https://en.wikipedia.org/wiki/Meta_learning_(computer_science)*\\\n",
    "**[4] C. Finn, P. Abbeel, S. Levine (2017):** *Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "59f3145cc67fcda0343c2852f1f97113a2e6e98841e887156424448e7071ad54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
